{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier\n",
    "Lets start with a simple linear classifier Perceptron.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html\n",
    "\n",
    "## Generating Some Linear Separable Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "numSamples = 300\n",
    "samples,labels = make_blobs(n_samples=numSamples, \n",
    "                             centers=([1.5, 3], [6.7, 7.9]), \n",
    "                             random_state=0)\n",
    "colours = ('red', 'blue')\n",
    "fig, ax = plt.subplots()\n",
    "for n_class in range(2):\n",
    "    ax.scatter(samples[labels==n_class][:, 0], samples[labels==n_class][:, 1], \n",
    "               c=colours[n_class], s=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Vectorization\n",
    "Take a look at this cool post\n",
    "\n",
    "geeksforgeeks.org/vectorization-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_class = 1\n",
    "labels==n_class;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idx = np.empty(len(labels), dtype=bool)\n",
    "for i in range(1,len(labels)):\n",
    "    if (labels[i]==1):\n",
    "        idx[i] = 'True'\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "Learn it by Perceptron\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "trainData, testData, trainLabels,testLabels = train_test_split(samples , labels , test_size = 0.2, random_state=0)\n",
    "clf = Perceptron(tol=1e-1, max_iter = 3000, early_stopping= True)\n",
    "clf.fit(trainData,trainLabels)\n",
    "clf.predict(testData)\n",
    "colours = ('darkgreen', 'darkblue')\n",
    "fig, ax = plt.subplots()\n",
    "for n_class in range(2):\n",
    "    ax.scatter(trainData[trainLabels==n_class][:, 0], trainData[trainLabels==n_class][:, 1],c=colours[n_class],s=20)\n",
    "colours = ('lightgreen', 'lightblue')\n",
    "for n_class in range(2):\n",
    "    ax.scatter(testData[testLabels==n_class][:, 0], testData[testLabels==n_class][:, 1], \n",
    "               c=colours[n_class], s=20, label=str(n_class))\n",
    "w = clf.coef_[0]\n",
    "print(w)\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-1,9)\n",
    "# print(xx)\n",
    "yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "plt.plot(xx, yy, '--', color='red')\n",
    "print(clf.score(trainData,trainLabels))\n",
    "print(clf.score(testData,testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating non-linearly separable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons,make_circles\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples, labels = make_moons(n_samples=300, noise=0.1)\n",
    "# samples, labels = make_circles(n_samples=300, noise=0.05)\n",
    "trainData, testData, trainLabels,testLabels = train_test_split(samples , labels , test_size = 0.2)\n",
    "clf = Perceptron(tol=1e-3)\n",
    "clf.fit(trainData,trainLabels)\n",
    "clf.predict(testData)\n",
    "print(clf.score(testData,testLabels))\n",
    "# scatter plot, dots colored by class value\n",
    "\n",
    "colours = ('darkgreen', 'darkblue')\n",
    "fig, ax = plt.subplots()\n",
    "for n_class in range(2):\n",
    "    ax.scatter(trainData[trainLabels==n_class][:, 0], trainData[trainLabels==n_class][:, 1], \n",
    "               c=colours[n_class], s=40, label=str(n_class))\n",
    "colours = ('lightgreen', 'lightblue')\n",
    "for n_class in range(2):\n",
    "    ax.scatter(testData[testLabels==n_class][:, 0], testData[testLabels==n_class][:, 1], \n",
    "               c=colours[n_class], s=40, label=str(n_class))\n",
    "# fig, ax = plt.subplots()\n",
    "w = clf.coef_[0]\n",
    "print(w)\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-1.5, 4)\n",
    "yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "plt.plot(xx, yy, '--', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer non-linear neural network\n",
    "\n",
    "Code is based on: https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook about Stochastic Gradient Descent (SGD): \n",
    "https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Classification/Stochastic_grad_descent.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  solver: lbfgs, sgd(Stochiastic Gradient Descent) and Adam \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20), max_iter=2000, alpha=0.1,\n",
    "                    solver='adam',\n",
    "                    learning_rate_init=0.001, learning_rate='adaptive')\n",
    "mlp.fit(trainData, trainLabels);\n",
    "mlp.predict(testData)\n",
    "print(mlp.score(testData,testLabels))\n",
    "\n",
    "h=0.2 #step-size\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "x_min, x_max = samples[:, 0].min() - .5, samples[:, 0].max() + .5\n",
    "y_min, y_max = samples[:, 1].min() - .5, samples[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "print(xx.ravel().shape)\n",
    "print(yy.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(trainData[:, 0], trainData[:, 1])\n",
    "    # and testing points\n",
    "ax.scatter(testData[:, 0], testData[:, 1], cmap=cm_bright, alpha=0.6)\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "if hasattr(mlp, \"decision_function\"):\n",
    "    Z = mlp.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "else:\n",
    "    Z = mlp.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "# ax.contourf(xx, yy, Z, cmap=cm, alpha=.001)\n",
    "\n",
    "        # Plot also the training points\n",
    "ax.scatter(trainData[:, 0], trainData[:, 1],edgecolors='black', s=25)\n",
    "ax.scatter(testData[:, 0], testData[:, 1], edgecolors='black', s=25)\n",
    "name=\"Decision function\"\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(name)\n",
    "ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % mlp.score(testData,testLabels)).lstrip('0'),size=15, horizontalalignment='right')\n",
    "Z = Z.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, Z, cmap=cm, alpha=0.67)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand-Written digits:\n",
    "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "images = load_digits()\n",
    "plt.gray()\n",
    "plt.matshow(images.images[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment\n",
    "\n",
    "Running experiment on number of neurons in the hidden layer and the value of regularization($\\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "X_scaled = preprocessing.scale(X_digits)\n",
    "trainData,testData,trainLabel,testLabel =train_test_split(X_scaled,y_digits,test_size=0.2)\n",
    "\n",
    "# ======== Running Experiments on number of neurons in the hidden layer\n",
    "\n",
    "clf_1 = MLPClassifier(hidden_layer_sizes=(3), max_iter=1300, alpha=1e-4,solver='sgd', learning_rate_init=.01)\n",
    "clf_1.fit(trainData,trainLabel)\n",
    "print(clf_1.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using 3 neurons in the hidden layer:%.4f\"%clf_1.score(testData,testLabel))\n",
    "\n",
    "clf_2 = MLPClassifier(hidden_layer_sizes=(7), max_iter=1300, alpha=1e-4,solver='sgd', learning_rate_init=.01)\n",
    "clf_2.fit(trainData,trainLabel)\n",
    "print(clf_2.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using 7 neurons in the hidden layer:%.4f\"%clf_2.score(testData,testLabel))\n",
    "\n",
    "\n",
    "clf_3 = MLPClassifier(hidden_layer_sizes=(13), max_iter=1300, alpha=1e-4,solver='sgd', learning_rate_init=.01)\n",
    "clf_3.fit(trainData,trainLabel)\n",
    "print(clf_3.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using 13 neurons in the hidden layer:%.4f\"%clf_3.score(testData,testLabel))\n",
    "\n",
    "clf_4 = MLPClassifier(hidden_layer_sizes=(21), max_iter=1300, alpha=1e-4,solver='sgd', learning_rate_init=.01)\n",
    "clf_4.fit(trainData,trainLabel)\n",
    "print(clf_4.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using 21 neurons in the hidden layer:%.4f\"%clf_4.score(testData,testLabel))\n",
    "\n",
    "# ============================== Running Experiments on alpha parameter\n",
    "clf_5 = MLPClassifier(hidden_layer_sizes=(4),alpha=1,max_iter=1300,solver='sgd', learning_rate_init=.01)\n",
    "clf_5.fit(trainData,trainLabel)\n",
    "print(clf_5.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using alpha=1:%.4f\"%clf_5.score(testData,testLabel))\n",
    "\n",
    "clf_6 = MLPClassifier(hidden_layer_sizes=(4),alpha=1e-1,max_iter=1300,solver='sgd', learning_rate_init=.01)\n",
    "clf_6.fit(trainData,trainLabel)\n",
    "print(clf_6.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using alpha=0.1:%.4f\"%clf_6.score(testData,testLabel))\n",
    "\n",
    "clf_7 = MLPClassifier(hidden_layer_sizes=(4),alpha=1e-2,max_iter=1300,solver='sgd', learning_rate_init=.01)\n",
    "clf_7.fit(trainData,trainLabel)\n",
    "print(clf_7.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using alpha=0.01:%.4f\"%clf_7.score(testData,testLabel))\n",
    "\n",
    "clf_8 = MLPClassifier(hidden_layer_sizes=(4),alpha=1e-3,max_iter=1300,solver='sgd', learning_rate_init=.01)\n",
    "clf_8.fit(trainData,trainLabel)\n",
    "print(clf_8.score(trainData,trainLabel))\n",
    "print(\"Accuracy of using alpha=0.001:%.4f\"%clf_8.score(testData,testLabel))\n",
    "\n",
    "\n",
    "# ============== Plotting in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "Ploting results from above cell. Please, look at the following link to get more infoamtion:\n",
    "https://matplotlib.org/devdocs/gallery/subplots_axes_and_figures/subplots_demo.html\n",
    "\n",
    "https://matplotlib.org/tutorials/introductory/pyplot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(14,6))\n",
    "axs[0].plot(clf_1.loss_curve_,'r--', label='3-neurons')\n",
    "axs[0].plot(clf_2.loss_curve_,'b--',label='7-neurons')\n",
    "axs[0].plot(clf_3.loss_curve_,'y--',label='13-neurons')\n",
    "axs[0].plot(clf_4.loss_curve_,'g--',label='21-neurons')\n",
    "axs[0].grid('True')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(clf_5.loss_curve_, 'r--' , label='alpha=1')\n",
    "axs[1].plot(clf_6.loss_curve_, 'b--' , label='alpha=0.1')\n",
    "axs[1].plot(clf_7.loss_curve_, 'y--' , label='alpha=0.01')\n",
    "axs[1].plot(clf_8.loss_curve_, 'g--' , label='alpha=0.001')\n",
    "axs[1].grid('True')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch\n",
    "Finding the best hyperparameter using built-in GridSearch function inside the sklearn package\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "A useful example: \n",
    "https://www.kaggle.com/hatone/mlpclassifier-with-gridsearchcv#L71\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "parameters = {'solver': ['lbfgs','sgd'], 'max_iter': [200,300,120],\n",
    "              'alpha': 10.0 ** -np.arange(0, 3), 'hidden_layer_sizes':np.arange(10, 15)} \n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
    "clf.fit(trainData,trainLabel)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
